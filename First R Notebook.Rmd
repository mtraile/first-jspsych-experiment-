---
title: "First R Notebook"
author: "Mitri Traile"
date: "2024-10-15"
output: html_document
---
# install packages 
```{r}
# install.packages("tidyverse")
```

# load packages
```{r}
library(tidyverse)
```
# plot iris 
```{r}
ggplot(data=iris)+
  geom_point(mapping=aes(x=Petal.Width, y= Petal.Length, color=Species, size= Species, shape= Species))


ggplot(data=iris)+
  geom_line(mapping=aes(x= Sepal.Width, y= Sepal.Length, color= Species, size= Species, shape= Species))


ggplot(data=iris)+
  geom_col(mapping= aes(x= Species, y= Petal.Length), fill= "lightblue")+ theme_test()
```
# load class data
```{r}
savic=read_csv("class_data.csv")
```
# basic info
```{r}
nrow(savic)
ncol(savic)
colnames(savic)
mean (savic$correct)
```
# plot reaction time
```{r}
ggplot(data=savic)+
  geom_histogram (mapping=aes(x=as.numeric(rt)))
range(as.numeric(savic$rt))
```
```{r}

```
# tidyverse verbs 
```{r}
objectdata= read_csv("objects.csv")%>%
  mutate(rt= as.numeric(rt),
         weight= as.factor(weight),
         shape= as.factor(shape))
nrow("objects.csv")
ncol("objects.csv")
colnames("objects.csv")
condition_data= objectdata %>%
  filter(typeoftrial == "picture" & weight %in% c("Heavy", "Light") & 
  shape %in% c("Normal", "Smashed") &
  correct == TRUE) %>%
  select(subject,rt, weight, shape, correct)
condition_data %>%
  summarise(mean_rt = mean (rt))
object_agg = condition_data %>%
  group_by(weight,shape) %>%
  summarise(mean_rt = mean(rt),
            sd_rt= sd(rt))

ggplot(data= object_agg) +
  geom_col(mapping = aes(x= shape, y= mean_rt, fill= weight),
           position= "dodge") +
  theme_test()+ 
  labs(title= "plot of RTs")+
  scale_fill_manual(values= c("red", "skyblue"))
```
# class data analysis 
```{r}
savic=read_csv("class_data.csv")%>%
  mutate(rt=as.numeric(rt),
         relatedness= as.factor(relatedness),
         type= as.factor(type))
levels(savic$relatedness)
savic%>% group_by(ID) %>% count()

savic%>% filter(typeoftrial == "target") %>%
  group_by(ID) %>% count()
x= savic%>% filter(typeoftrial == "target") %>%
  group_by(ID) %>% count() %>%
  filter(n != 104)

mean(x$n)

savic%>% 
  filter(typeoftrial == "target") %>%
  pull(rt)

savic%>% 
  pull(ID) %>% unique() %>% length()
```
#attention 
```{r}
  attention_trials= savic%>%filter(typeoftrial == "attention") %>%
  select(ID,response,novel1,novel2,novel3,correct) %>%
rowwise() %>%
  mutate(response= ifelse(is.na(response), "blank", response)) %>%
  mutate(across(c(novel1, novel2, novel3), ~ replace_na(., "NOT_FOUND"))) %>%
  mutate(edit_novel1 = adist(novel1, response),
         edit_novel2= adist(novel2, response),
         edit_novel3= adist(novel3, response)) %>%
  mutate(revised_correct = ifelse(edit_novel1 <2|
                                    edit_novel2 <2 |
                                    edit_novel3 <2,
                                  1,0),
                        mismatch= ifelse(correct == revised_correct, 0,1)) %>%
           ungroup()
## mean 

attention_trials %>%
  summarize(mean_accuracy= mean (revised_correct),
            sd_accuracy= sd(revised_correct))

## summarize participant accuracy 
subject_attention_accuracy = attention_trials %>%
  group_by(ID) %>%
  summarize (mean_accuracy = mean (revised_correct))

##find IDs that have less than 75% accuracy

low_acc_IDs = subject_attention_accuracy %>%
  filter (mean_accuracy < 0.75) %>%
  pull(ID)
```

# priming analysis 

```{r}
priming_data= savic%>% filter(typeoftrial == "target") %>%
  select (ID, rt, relatedness, prime, response,type, correct, block_number, target, correct_key) %>%
  filter(!is.na(rt), rt> 200, rt< 1500, correct == "TRUE", block_number == 1) %>%
  filter(relatedness %in% c("related", "unrelated") & type %in% c("direct", "shared")) %>%
filter(!ID %in% low_acc_IDs)
```
## plot 
```{r}
priming_data %>%
  group_by(type, relatedness) %>%
  summarise(mean_rt = mean(rt)) %>%
  ggplot() +
  geom_col(mapping= aes(x= type, y= mean_rt, 
                        group= relatedness, fill= relatedness),
           position = "dodge") +
  theme_bw() +
  scale_fill_grey()
```
# linear models
```{r}
data(women)
women %>%
ggplot(aes(x=weight, y=height)) +
  geom_point()+
geom_smooth(method= "lm" )+
  theme_classic()
```

# load packages
```{r}
library(tidyverse)
```

```{r}
women %>%
ggplot(aes(x=weight, y=height)) +
  geom_point()+
geom_smooth(method= "lm" )+
  theme_classic()
women_model = lm(data = women,height ~weight)
summary(women_model)
```

#install car package
```{r}
#install.packages("car")
car:: Anova(women_model)
```
# iris again 
```{r}
data(iris)
View(iris)

iris%>%
  group_by(Species)%>%
  summarise(mean_length=mean(Petal.Length))

iris%>%
  ggplot(aes(x=Species, y=Petal.Length))+
geom_boxplot()+
theme_classic()
```
#ANOVA for iris 
```{r}
iris_model=lm(data = iris, Petal.Length~Species)
car:: Anova(iris_model)
```
Species sig predicted petal length, F(2,147) = 1180.2, p< 0.001
# install emmeans
```{r}
#install.packages("emmeans")
emmeans:: emmeans(iris_model,
                  pairwise~ Species,
                  adjust= "tukey")
```
Follow up tests indicate that setosa's petal length is sig diff from both versicolor (t(147)= -32.51, p<.001) and virginica(t(147)=-47.521, p<.0001)

```{r}
priming_data %>%
  group_by(ID,relatedness,type)%>%
  count()
```
#install new package with multiple IVS
```{r}
install.packages("datarium")
```
```{r}
library(datarium)
```

```{r}
data("jobsatisfaction", package = "datarium")
View(jobsatisfaction)
```

#to visualize
```{r}
jobsatisfaction%>%
ggplot()+
  geom_boxplot(mapping = aes(x = gender, y = score, fill = education_level))
```
#reminder interaction is intersecting lines on plot. difference in means between IV1s levels differ based on levels of IV2

#separate terms for main effects and interactions
```{r}
job_model = lm(data = jobsatisfaction, score ~ gender + education_level +gender:education_level)

car :: Anova(job_model)
```
#interaction with gender and education level. no main effect 
#An ANOVA was conducted. No main effect of gender was reported (F(1, 52)= 0.75, p = 0.392.
#There is a main effect of education level (F(2, 52)= 187.89, p < 0.001).
#There is also a significant interaction between gender and education (F(2, 52)= 7.339, p = 0.002)

#using this for pairwise comparisons

```{r}
emmeans :: emmeans (job_model,
                    pairwise~ gender | education_level,
                    adjust = "tukey")
```

#Looking for something goin on in the contrast area.
#Tukey adjust follow-up t-tyests indicate that male vs female job interaction level does not deviate significantly at the college or school level but males have higher job satusfaction at tge university level compared to females.
#ASSUMPTIONS
#lm is the assumption that data can be broken down linearly (no squared or cubed terms)
#normality of residuals. whatever is leftover from the model is normally distributed
#homogeneity of variance
#independence of variance. no within-subjects observations with data. all between-subjects

#Inspecting the model
```{r}
#install.packages("performance", dependencies = TRUE)
#install.packages("see", dependencies = TRUE)
#install.packages("patchwork", dependencies = TRUE)
```

```{r}
library(performance)
check_model(job_model)
```
#Gives you what is expected as a description and then shows you the plot of your data. Ours is not perefcet but it is okay.No major violations in assumptions were depicted here.

```{r}
priming_data %>% count()
```
#Checked that this has 492 particiopants

```{r}
rt_lm_model = lm(data = priming_data, rt ~relatedness + type + relatedness : type)
car :: Anova(rt_lm_model)
check_model(rt_lm_model)
```
#We have multiple observations for the same person because one person is doing the different conditions (unrelated shared and shared related), so we cannot use the ANOVA because this is not independent

#want to use Repeated Measure ANOVA for our data
```{r}
savic %>% 
  filter(typeoftrial == "target") %>%
  filter(relatedness %in% c("related", "unrelated") & type %in% c("direct", "shared")) %>% 
  group_by(ID, relatedness, type) %>% 
  count()
```
#Each participnat did 16 trials of each one with equal number of trials before exclusions.

#
```{r}
priming_data %>%
  group_by(ID, relatedness, type) %>%
  count()
```
#Incorrect trials or bad reaction time resulted in removing trials. Unbalanced reepeated measures (time)
#ANOVA limited by continuous DVs (accuracy is not continuous), can only do categorical IVs, cannot deal with missing data, cannot handle nestered/clustered data/ cannot handle unbalanced data

#solution is flexible LINEAR MIXED EFFECTS MODEL. parents of anova and t-test
```{r}
#install.packages("lmerTest")
library(lmerTest)

rt_model = lmer(data =priming_data, rt~ relatedness*type + (1|ID))
```
#lmer linear mixed effects model
#relatedness*type is shorthand for relatedness +type +
#unit of analysis is at the level of the individual

```{r}
car::Anova(rt_model)
nobs(rt_model)
check_model = rt_model
```
#report a chi square
```{r}
#install.packages("ggthemes")
```

```{r}
library(ggthemes)
```
# reproduce plot 
```{r}
counts= jobsatisfaction%>%
  group_by(gender,education_level)%>%
  count()

mean_scores= jobsatisfaction%>%
  group_by(gender, education_level) %>%
  summarise(mean_score= mean(score), sd_score= sd(score))%>%
left_join(counts)%>%
  mutate(SE= sd_score/n,
         ymin= mean_score - 1.96*SE,
         ymax= mean_score + 1.96* SE)


mean_scores %>%
ggplot(aes(x = education_level, y = mean_score, fill = gender)) +
  geom_col (position = "dodge")+
  geom_errorbar(aes(ymin = ymin, ymax= ymax),
                width= .25,
                position = position_dodge(width= .9))+
  geom_point(data= jobsatisfaction, aes(x= education_level, y= score, group= gender),
             position= position_jitterdodge(),
             alpha= 0.3)

```
```{r}
unique_values= unique(final_data$correct)
print(unique_values)
```

